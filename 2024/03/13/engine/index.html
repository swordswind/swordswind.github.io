<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/icons/favicon-16x16.png?v=2.6.2" type="image/png" sizes="16x16"><link rel="icon" href="/images/icons/favicon-32x32.png?v=2.6.2" type="image/png" sizes="32x32"><meta name="description" content="​    · 在硬件条件充足的情况下，可采用本地部署AI的方案，具有低延迟、低风险、低依赖、低漏洞、低限制、低成本的优势。获取DLC，开启本地端侧AI引擎，数据无需上传云端。下述DLC均为免费的开源项目，不仅支持对接AI虚拟伙伴，也支持对接第三方软件，或遵循开源协议自由二次开发应用。">
<meta property="og:type" content="article">
<meta property="og:title" content="本地端侧AI引擎DLC指引">
<meta property="og:url" content="https://swordswind.github.io/2024/03/13/engine/index.html">
<meta property="og:site_name" content="MewCo-AI Studio">
<meta property="og:description" content="​    · 在硬件条件充足的情况下，可采用本地部署AI的方案，具有低延迟、低风险、低依赖、低漏洞、低限制、低成本的优势。获取DLC，开启本地端侧AI引擎，数据无需上传云端。下述DLC均为免费的开源项目，不仅支持对接AI虚拟伙伴，也支持对接第三方软件，或遵循开源协议自由二次开发应用。">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2024-03-13T12:46:59.421Z">
<meta property="article:modified_time" content="2026-02-13T02:46:33.767Z">
<meta property="article:author" content="MewCo-AI工作室">
<meta property="article:tag" content="swordswind MewCo-AI工作室">
<meta name="twitter:card" content="summary"><title>本地端侧AI引擎DLC指引 | MewCo-AI Studio</title><link ref="canonical" href="https://swordswind.github.io/2024/03/13/engine/"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.6.2"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  assistSearch: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":true,"scrollDownIcon":false},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"复制","copySuccess":"复制成功","copyError":"复制失败"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 5.4.0"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">首页</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">新闻动态</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/categories/"><span class="header-nav-menu-item__icon"><i class="fas fa-layer-group"></i></span><span class="header-nav-menu-item__text">项目一览</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/about/"><span class="header-nav-menu-item__icon"><i class="fas fa-link"></i></span><span class="header-nav-menu-item__text">关于我们</span></a></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"><div class="header-banner-info"><div class="header-banner-info__title">MewCo-AI Studio</div><div class="header-banner-info__subtitle">科技之花应自由绽放，为文明进步铺设舞台</div></div></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content" id="content"><!-- Just used to judge whether it is an article page--><div id="is-post"></div><div class="post"><header class="post-header"><h1 class="post-title">本地端侧AI引擎DLC指引</h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2024-03-13</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2026-02-13</span></span><span class="post-meta-item post-meta-item--visitors"><span class="post-meta-item__icon"><i class="fas fa-eye"></i></span><span class="post-meta-item__info">阅读次数</span><span class="post-meta-item__value" id="busuanzi_value_page_pv"></span></span></div></header><div class="post-body"><p>​    · 在硬件条件充足的情况下，可采用本地部署AI的方案，具有<strong>低延迟、低风险、低依赖、低漏洞、低限制、低成本</strong>的优势。获取DLC，开启本地端侧AI引擎，数据无需上传云端。下述DLC均为<strong>免费的开源项目</strong>，不仅支持对接AI虚拟伙伴，也支持对接第三方软件，或遵循开源协议自由二次开发应用。<span id="more"></span><br>(支持对接的AI虚拟伙伴版本尾注：E-探索版、C-社区版、L-Linux版)</p>

        <h3 id="本地对话大语言模型类"   >
          <a href="#本地对话大语言模型类" class="heading-link"><i class="fas fa-link"></i></a><a href="#本地对话大语言模型类" class="headerlink" title="本地对话大语言模型类"></a><center>本地对话大语言模型类</center></h3>
      <p>​    <strong>Transformers整合包</strong>：整合了HF的Transformers框架API服务器、阿里的Qwen3-0.6B大语言模型和Python运行环境。仅支持CPU运行，速度较慢，供入门学习。(E,C)<br><span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://pan.baidu.com/s/10E3dSoA0TnA3gBmROJsiBA?pwd=aivm" >免费获取 ↓ 1.42G</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/huggingface/transformers" >开源地址</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1M3pXzKExD" >配置教程</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span><br>​    <strong>Ollama框架</strong>：支持用命令行一键下载安装市面上的主流大模型，基于llama.cpp框架，有简易的图形界面。支持CPU、N卡、A卡运行，智能动态分配计算资源，<strong>非常推荐</strong>。(E,C,L)<br><span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://ollama.com/download" >免费获取</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/ollama/ollama" >开源地址</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1r7421d7yA" >配置教程</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span><br>​    <strong>LM Studio框架</strong>：支持运行市面上的主流的GGUF大模型，基于llama.cpp框架，有丰富的图形界面。支持CPU、N卡、A卡、Vulkan核显运行。(E,C,L)<br><span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://lmstudio.ai/" >免费获取</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/lmstudio-ai/lmstudio-python" >开源地址</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1K7421Z7k1" >配置教程</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span><br>​    <strong>AnythingLLM知识库</strong>：允许用户上传知识库(任何文档、资源或内容片段)转化为大语言模型在聊天中可利用的相关上下文。支持对接OpenAI兼容接口的大模型。(E,C,L)<br><span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://anythingllm.com/download" >免费获取</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/Mintplex-Labs/anything-llm" >开源地址</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1aTxMehEbb" >配置教程</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span><br>​    <strong>Dify聊天助手知识库</strong>：开源的LLM应用开发平台，支持用户上传知识库。功能强大，部署难度较高，需要熟悉虚拟机、Linux系统、Docker。(E,C,L)<br><span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/langgenius/dify" >开源地址</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1YNLnzeE4r" >配置教程</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span><br>​    <strong>RKLLM框架整合包</strong>：Rockchip推出的工具链，用于将LLM高效部署到其支持NPU的平台，支持模型转换与量化(如w4a16、w8a8)，实现硬件加速推理。(L,仅适用于RK3588/3576芯片)<br><span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://pan.baidu.com/s/1LUGdbDJi1wngGnF165QDVA?pwd=aivm" >免费获取 ↓ 2M</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/wudingjian/rkllm_chat/tree/main/rkllm_server" >开源地址</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1pW8CzDE2r" >配置教程</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>

        <h3 id="本地语音合成大模型类"   >
          <a href="#本地语音合成大模型类" class="heading-link"><i class="fas fa-link"></i></a><a href="#本地语音合成大模型类" class="headerlink" title="本地语音合成大模型类"></a><center>本地语音合成大模型类</center></h3>
      <p>​    <strong>GPT-SoVITS整合包</strong>：RVC-Boss(花儿不哭)大佬团队开发的GPT-SoVITS语音合成大模型v2ProPlus-250604官方API整合包。支持CPU、N卡运行，并且适配最新的<strong>50系</strong>N卡。具有低显存占用且速度快的优势，<strong>非常推荐</strong>。(E,C,L)<br><span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://www.modelscope.cn/models/FlowerCry/gpt-sovits-7z-pacakges/resolve/master/GPT-SoVITS-v2pro-20250604-nvidia50.7z" >免费获取 ↓ 8.19G</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://pan.baidu.com/s/19p29dxbMp4i2LLqGyw2igw?pwd=aivm" >GPT-SoVITS适配AI虚拟伙伴补丁 ↓ 126KB</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/RVC-Boss/GPT-SoVITS" >开源地址</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1QCpTz1E3q" >配置教程</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span><br>​    <strong>CosyVoice整合包</strong>：整合了语音合成大模型API服务器、阿里FunAudioLLM开发的CosyVoice语音合成大模型1代300M/2代0.5B和Python运行环境。支持CPU、N卡运行。(E,C,L)<br><span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://pan.baidu.com/s/1I-ak8PoCVRcH_qQCD4gpkg?pwd=aivm" >免费获取1代 ↓ 4.98G</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://pan.baidu.com/s/1zfMQQykN2OBYGVVc7RJ4oA?pwd=aivm" >免费获取2代 ↓ 6.17G</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/FunAudioLLM/CosyVoice" >开源地址</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV127UrYpEjb" >配置教程</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span><br>​    <strong>Index-TTS整合包</strong>：整合了语音合成大模型API服务器、B站开发的Index-TTS语音合成大模型和Python运行环境。支持CPU、N卡运行。(E,C,L)<br><span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://pan.baidu.com/s/15MbpQVfKMXUFztfYuKKcEA?pwd=aivm" >免费获取 ↓ 6.37G</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/index-tts/index-tts" >开源地址</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Eb5yzGERH" >配置教程</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span><br>​    <strong>VoxCPM整合包</strong>：整合了语音合成大模型API服务器、OpenBMB团队开发的VoxCPM语音合成大模型1.5-0.5B和Python运行环境。仅支持N卡运行。(C,L)<br><span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://pan.baidu.com/s/1rjJtdIoYtep4f0jXALKwTQ?pwd=aivm" >免费获取 ↓ 4.68G</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/OpenBMB/VoxCPM" >开源地址</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV11gUwBPEUk" >配置教程</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span><br>​    <strong>Qwen-TTS整合包</strong>：整合了语音合成大模型API服务器、阿里通义团队开发的Qwen3-TTS语音合成大模型0.6B和Python运行环境。支持CPU、N卡运行。(L)<br><span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://pan.baidu.com/s/1M_1Oxjm87krGhe-cEmeMXw?pwd=aivm" >免费获取 ↓ 5.08G</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/QwenLM/Qwen3-TTS" >开源地址</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>

        <h3 id="本地多模态图像识别-生成类"   >
          <a href="#本地多模态图像识别-生成类" class="heading-link"><i class="fas fa-link"></i></a><a href="#本地多模态图像识别-生成类" class="headerlink" title="本地多模态图像识别/生成类"></a><center>本地多模态图像识别/生成类</center></h3>
      <p>​    <strong>Ollama VLM指引</strong>：下载安装大模型引擎Ollama后，在命令行输入“ollama pull qwen3-vl:2b-instruct”，等待下载完成，然后在AI虚拟伙伴的软件设置修改对应Ollama多模态名称，保存重启软件后左侧图像识别引擎中选择“本地Ollama VLM”。占用显存中等，效果较好，<strong>非常推荐</strong>。(E,C,L)<br><span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1fZy6YhEHd" >配置教程</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span><br>​    <strong>LM Studio VLM指引</strong>：下载安装大模型引擎LM Studio后，进入并下载想要运行的VLM模型后，开启API服务器，然后在AI虚拟伙伴的左侧图像识别引擎中选择“本地LM Studio”。(C,L)<br><span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://pan.baidu.com/s/1x7MbZM1hVed1kLAUDsgDQA?pwd=aivm" >免费获取 ↓ 5.26G</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/QwenLM/Qwen2.5-VL" >开源地址</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1D7BBYbEzh" >配置教程</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span><br>​    <strong>Janus-Pro整合包</strong>：整合了多模态大模型API服务器、DeepSeek的Janus-Pro-1B多模态大模型和Python运行环境。支持CPU、N卡运行。占用显存中等，效果良好。不仅支持图像识别，还支持<strong>图像生成AI绘画</strong>。(E,C)<br><span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://pan.baidu.com/s/1Zm-TWdI8SGx5AAP-lhCq6A?pwd=aivm" >免费获取 ↓ 5.66G</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/deepseek-ai/Janus" >开源地址</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1qgFHe1EXW" >配置教程</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>

        <h3 id="其他本地端侧AI引擎-独立运行-不支持对接AI伙伴"   >
          <a href="#其他本地端侧AI引擎-独立运行-不支持对接AI伙伴" class="heading-link"><i class="fas fa-link"></i></a><a href="#其他本地端侧AI引擎-独立运行-不支持对接AI伙伴" class="headerlink" title="其他本地端侧AI引擎(独立运行,不支持对接AI伙伴)"></a><center>其他本地端侧AI引擎(独立运行,不支持对接AI伙伴)</center></h3>
      <p>​    <strong>Qwen2.5-Omni整合包</strong>：整合了阿里的Qwen2.5-Omni-3B端到端全模态大模型和Python运行环境。需要至少16G显存的N卡运行。输入支持视频、图像、语音、文字，输出支持语音、文字。<br><span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://pan.baidu.com/s/1ZgsrJ51KSznFtmDIWB4boQ?pwd=aivm" >免费获取 ↓ 11.7G</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/QwenLM/Qwen2.5-Omni" >开源地址</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1i7V8z8EQk" >使用教程</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span><br>​    <strong>MNN Chat手机安装包</strong>：采用了阿里开源的端侧轻量级AI推理引擎MNN框架，手机也能畅玩本地多模态大模型，支持Qwen、DeepSeek、MiniCPM等模型。<br><span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/alibaba/MNN/blob/master/apps/Android/MnnLlmChat/README.md#releases" >免费获取(Android) ↓</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/alibaba/MNN/tree/master/apps/Android/MnnLlmChat" >开源地址</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>  <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1wzjyzpE9j" >使用教程</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
</div><footer class="post-footer"><div class="post-ending ending"><div class="ending__text">------ 本文结束，感谢您的阅读 ------</div></div><nav class="post-paginator paginator"><div class="paginator-prev"><a class="paginator-prev__link" href="/2024/07/09/mateweb/"><span class="paginator-prev__icon"><i class="fas fa-angle-left"></i></span><span class="paginator-prev__text">枫云AI虚拟伙伴社区版(开源)</span></a></div></nav></footer></div></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><div class="sidebar-nav"><span class="sidebar-nav-toc current">文章目录</span><span class="sidebar-nav-ov">官网概览</span></div><section class="sidebar-toc"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%AC%E5%9C%B0%E5%AF%B9%E8%AF%9D%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%B1%BB"><span class="toc-number">1.</span> <span class="toc-text">
          本地对话大语言模型类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%AC%E5%9C%B0%E8%AF%AD%E9%9F%B3%E5%90%88%E6%88%90%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B1%BB"><span class="toc-number">2.</span> <span class="toc-text">
          本地语音合成大模型类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%AC%E5%9C%B0%E5%A4%9A%E6%A8%A1%E6%80%81%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-%E7%94%9F%E6%88%90%E7%B1%BB"><span class="toc-number">3.</span> <span class="toc-text">
          本地多模态图像识别&#x2F;生成类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E6%9C%AC%E5%9C%B0%E7%AB%AF%E4%BE%A7AI%E5%BC%95%E6%93%8E-%E7%8B%AC%E7%AB%8B%E8%BF%90%E8%A1%8C-%E4%B8%8D%E6%94%AF%E6%8C%81%E5%AF%B9%E6%8E%A5AI%E4%BC%99%E4%BC%B4"><span class="toc-number">4.</span> <span class="toc-text">
          其他本地端侧AI引擎(独立运行,不支持对接AI伙伴)</span></a></li></ol></section><!-- ov = overview--><section class="sidebar-ov hide"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/images/icons/stun-logo.jpg" alt="avatar"></div><p class="sidebar-ov-author__text">SwordsWind Blog</p></div><div class="sidebar-ov-social"><a class="sidebar-ov-social-item" href="https://github.com/MewCo-AI/" target="_blank" rel="noopener"><span class="sidebar-ov-social-item__icon"><i class="fab fa-github"></i></span><span class="sidebar-ov-social-item__text">GitHub</span></a><a class="sidebar-ov-social-item" href="https://space.bilibili.com/106439263/" target="_blank" rel="noopener"><span class="sidebar-ov-social-item__icon"><i class="fab fa-youtube"></i></span><span class="sidebar-ov-social-item__text">Bilibili</span></a></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">7</div><div class="sidebar-ov-state-item__name">新闻动态</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--categories" href="/categories/"><div class="sidebar-ov-state-item__count">0</div><div class="sidebar-ov-state-item__name">项目一览</div></a></div></section><div class="sidebar-reading"><div class="sidebar-reading-info"><span class="sidebar-reading-info__text">你已阅读了 </span><span class="sidebar-reading-info__num">0</span><span class="sidebar-reading-info__perc">%</span></div><div class="sidebar-reading-line"></div></div></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2026</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>MewCo-AI工作室</span></div><div class="busuanzi"><span class="busuanzi-siteuv"><span class="busuanzi-siteuv__icon"><i class="fas fa-user"></i></span><span class="busuanzi-siteuv__info">访问人数</span><span class="busuanzi-siteuv__value" id="busuanzi_value_site_uv"></span></span><span class="busuanzi-sitepv"><span class="busuanzi-siteuv__icon"><i class="fas fa-eye"></i></span><span class="busuanzi-siteuv__info">浏览总量</span><span class="busuanzi-siteuv__value" id="busuanzi_value_site_pv"></span></span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="https://cdn.jsdelivr.net/gh/sukkaw/busuanzi@latest/bsz.pure.mini.js" async></script><script src="/js/utils.js?v=2.6.2"></script><script src="/js/stun-boot.js?v=2.6.2"></script><script src="/js/scroll.js?v=2.6.2"></script><script src="/js/header.js?v=2.6.2"></script><script src="/js/sidebar.js?v=2.6.2"></script></body></html>